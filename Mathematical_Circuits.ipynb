{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mathematical Circuits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Using {DEVICE}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Neural_Net(layer_sizes, bias=True, verbose=True):\n",
    "    assert(len(layer_sizes) >= 2)\n",
    "    \n",
    "    # Get individual layer pieces:\n",
    "    #  - Each layer is linear\n",
    "    #  - All hidden layers have ReLU activation\n",
    "    layers = []\n",
    "    for i in range(len(layer_sizes) - 1):\n",
    "        if i == len(layer_sizes) - 2:  # Last (output) layer\n",
    "            layers += [nn.Linear(layer_sizes[i], layer_sizes[i+1], bias=bias)]\n",
    "        else:\n",
    "            layers += [\n",
    "                nn.Linear(layer_sizes[i], layer_sizes[i+1], bias=bias),\n",
    "                nn.ReLU()\n",
    "            ]\n",
    "    \n",
    "    # Model specification:\n",
    "    class NeuralNetwork(nn.Module):\n",
    "        def __init__(self):\n",
    "            super(NeuralNetwork, self).__init__()\n",
    "            self.NN = nn.Sequential(*layers)\n",
    "\n",
    "        def forward(self, x):\n",
    "            logits = self.NN(x)\n",
    "            return logits\n",
    "        \n",
    "        def print_model_parameters(self):\n",
    "            print(\"Weights:\")\n",
    "            print(\"--------\")\n",
    "\n",
    "            all_weights = list(self.parameters())\n",
    "            for i, layer_weights in enumerate(all_weights):\n",
    "                if i != (len(all_weights) - 1):\n",
    "                    print(f\"hidden_layer_{i}:\")\n",
    "                else:\n",
    "                    print(\"output_layer:\")\n",
    "\n",
    "                print(layer_weights.T)\n",
    "                print(\"\")\n",
    "\n",
    "        def _set_data_generators(self, generate_Xs, get_Ys):\n",
    "            self.generate_Xs = generate_Xs\n",
    "            self.get_Ys = get_Ys\n",
    "\n",
    "        def _init_loss_optimizer(self, lr=1e-1):\n",
    "            self.loss_fn = nn.MSELoss()\n",
    "            self.optimizer = torch.optim.SGD(self.parameters(), lr=lr)\n",
    "\n",
    "        def _init_test_data(self, test_n=1000, verbose=True):\n",
    "            self.test_X = self.generate_Xs(n=test_n)\n",
    "            self.test_y = self.get_Ys(self.test_X)\n",
    "\n",
    "            predicted = self(self.test_X)\n",
    "            loss = self.loss_fn(predicted, self.test_y).item()\n",
    "            if verbose: print(\"Starting Loss =\", loss)\n",
    "    \n",
    "    # Model initialization:\n",
    "    model = NeuralNetwork().to(DEVICE)\n",
    "    if verbose:\n",
    "        print(model)\n",
    "        print(\"\")\n",
    "        model.print_model_parameters()\n",
    "    return model\n",
    "\n",
    "def init_Neural_Net(layer_sizes, generate_Xs, get_Ys, bias=True, lr=1e-1, test_n=1000, verbose=True):\n",
    "    model = Neural_Net(layer_sizes, bias, verbose)\n",
    "    model._set_data_generators(generate_Xs, get_Ys)\n",
    "    model._init_loss_optimizer(lr)\n",
    "    model._init_test_data(test_n, verbose)\n",
    "    return model\n",
    "\n",
    "def train(model, batch_size=1000, batches_to_run=500, print_every=100):\n",
    "    for i in range(batches_to_run):\n",
    "        # Put model into training mode:\n",
    "        model.train()\n",
    "        \n",
    "        # Get current batch data\n",
    "        train_X = model.generate_Xs(n=batch_size)\n",
    "        train_y = model.get_Ys(train_X)\n",
    "        \n",
    "        # Do forward pass and evaluate loss\n",
    "        predicted = model(train_X)\n",
    "        loss = model.loss_fn(predicted, train_y)\n",
    "\n",
    "        # Backpropagation\n",
    "        model.optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        model.optimizer.step()\n",
    "\n",
    "        # Reporting\n",
    "        if i % print_every == 0:\n",
    "            model.eval()\n",
    "            predicted = model(model.test_X)\n",
    "            loss = model.loss_fn(predicted, model.test_y)\n",
    "            print(\"loss =\", loss.item())\n",
    "            # model.print_model_parameters()\n",
    "            print(\"\")\n",
    "\n",
    "    model.print_model_parameters()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Identity Function: f(x) = x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NeuralNetwork(\n",
      "  (NN): Sequential(\n",
      "    (0): Linear(in_features=1, out_features=2, bias=False)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=2, out_features=1, bias=False)\n",
      "  )\n",
      ")\n",
      "\n",
      "Weights:\n",
      "--------\n",
      "hidden_layer_0:\n",
      "tensor([[-0.0075,  0.5364]], grad_fn=<PermuteBackward0>)\n",
      "\n",
      "output_layer:\n",
      "tensor([[-0.5820],\n",
      "        [-0.5204]], grad_fn=<PermuteBackward0>)\n",
      "\n",
      "Starting Loss = 0.45063677430152893\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(0)  # Random seed\n",
    "\n",
    "def generate_Xs(n):\n",
    "    return torch.rand((n, 1)) * 2 - 1  # Uniform random between -1 and 1\n",
    "\n",
    "def get_Ys(Xs):\n",
    "    return Xs\n",
    "\n",
    "model = init_Neural_Net(\n",
    "    layer_sizes=(1, 2, 1),\n",
    "    bias=False,\n",
    "    generate_Xs=generate_Xs,\n",
    "    get_Ys=get_Ys\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss = 0.4366095960140228\n",
      "\n",
      "loss = 0.15338784456253052\n",
      "\n",
      "loss = 5.638498259941116e-05\n",
      "\n",
      "loss = 6.232232091507584e-11\n",
      "\n",
      "loss = 1.6763340390281434e-13\n",
      "\n",
      "Weights:\n",
      "--------\n",
      "hidden_layer_0:\n",
      "tensor([[-0.9212,  1.0036]], grad_fn=<PermuteBackward0>)\n",
      "\n",
      "output_layer:\n",
      "tensor([[-1.0855],\n",
      "        [ 0.9964]], grad_fn=<PermuteBackward0>)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train(\n",
    "    model,\n",
    "    batches_to_run=500\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Negative Identity Function: f(x) = -x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NeuralNetwork(\n",
      "  (NN): Sequential(\n",
      "    (0): Linear(in_features=1, out_features=2, bias=False)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=2, out_features=1, bias=False)\n",
      "  )\n",
      ")\n",
      "\n",
      "Weights:\n",
      "--------\n",
      "hidden_layer_0:\n",
      "tensor([[ 0.5153, -0.4414]], grad_fn=<PermuteBackward0>)\n",
      "\n",
      "output_layer:\n",
      "tensor([[-0.1371],\n",
      "        [ 0.3319]], grad_fn=<PermuteBackward0>)\n",
      "\n",
      "Starting Loss = 0.26709434390068054\n"
     ]
    }
   ],
   "source": [
    "# NOTE: Random seed 0 gets stuck in a local optimum where it works very well for positive inputs,\n",
    "# but always returns 0 for negative inputs:\n",
    "torch.manual_seed(1)  # Random seed\n",
    "\n",
    "def generate_Xs(n):\n",
    "    return torch.rand((n, 1)) * 2 - 1  # Uniform random between -1 and 1\n",
    "\n",
    "def get_Ys(Xs):\n",
    "    return Xs * -1\n",
    "\n",
    "model = init_Neural_Net(\n",
    "    layer_sizes=(1, 2, 1),\n",
    "    bias=False,\n",
    "    generate_Xs=generate_Xs,\n",
    "    get_Ys=get_Ys\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss = 0.2619011104106903\n",
      "\n",
      "loss = 1.8015611203736626e-05\n",
      "\n",
      "loss = 1.723086777427607e-11\n",
      "\n",
      "loss = 1.9885521452146088e-13\n",
      "\n",
      "loss = 1.8276527481101562e-13\n",
      "\n",
      "Weights:\n",
      "--------\n",
      "hidden_layer_0:\n",
      "tensor([[ 1.0619, -1.0210]], grad_fn=<PermuteBackward0>)\n",
      "\n",
      "output_layer:\n",
      "tensor([[-0.9417],\n",
      "        [ 0.9794]], grad_fn=<PermuteBackward0>)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train(\n",
    "    model,\n",
    "    batches_to_run=500\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Absolute Value: f(x) = |x|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NeuralNetwork(\n",
      "  (NN): Sequential(\n",
      "    (0): Linear(in_features=1, out_features=2, bias=False)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=2, out_features=1, bias=False)\n",
      "  )\n",
      ")\n",
      "\n",
      "Weights:\n",
      "--------\n",
      "hidden_layer_0:\n",
      "tensor([[ 0.5153, -0.4414]], grad_fn=<PermuteBackward0>)\n",
      "\n",
      "output_layer:\n",
      "tensor([[-0.1371],\n",
      "        [ 0.3319]], grad_fn=<PermuteBackward0>)\n",
      "\n",
      "Starting Loss = 0.31527942419052124\n"
     ]
    }
   ],
   "source": [
    "# NOTE: Random seed 0 gets stuck in a local optimum where the weight one of the hidden nodes gets zeroed out.\n",
    "# As a result ends up working for only positive inputs, but always returns 0 for negative inputs:\n",
    "torch.manual_seed(1)  # Random seed\n",
    "\n",
    "def generate_Xs(n):\n",
    "    return torch.rand((n, 1)) * 2 - 1  # Uniform random between -1 and 1\n",
    "\n",
    "def get_Ys(Xs):\n",
    "    return torch.abs(Xs)\n",
    "\n",
    "model = init_Neural_Net(\n",
    "    layer_sizes=(1, 2, 1),\n",
    "    bias=False,\n",
    "    generate_Xs=generate_Xs,\n",
    "    get_Ys=get_Ys\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss = 0.3092348575592041\n",
      "\n",
      "loss = 0.00012211436114739627\n",
      "\n",
      "loss = 1.1456475351723228e-10\n",
      "\n",
      "loss = 1.989102106766602e-13\n",
      "\n",
      "loss = 1.828202574136878e-13\n",
      "\n",
      "Weights:\n",
      "--------\n",
      "hidden_layer_0:\n",
      "tensor([[ 1.0608, -1.0210]], grad_fn=<PermuteBackward0>)\n",
      "\n",
      "output_layer:\n",
      "tensor([[0.9427],\n",
      "        [0.9794]], grad_fn=<PermuteBackward0>)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train(\n",
    "    model,\n",
    "    batches_to_run=500\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Addition: f(x1, x2) = x1 + x2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NeuralNetwork(\n",
      "  (NN): Sequential(\n",
      "    (0): Linear(in_features=2, out_features=2, bias=False)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=2, out_features=1, bias=False)\n",
      "  )\n",
      ")\n",
      "\n",
      "Weights:\n",
      "--------\n",
      "hidden_layer_0:\n",
      "tensor([[-0.0053, -0.5820],\n",
      "        [ 0.3793, -0.5204]], grad_fn=<PermuteBackward0>)\n",
      "\n",
      "output_layer:\n",
      "tensor([[-0.2723],\n",
      "        [ 0.1896]], grad_fn=<PermuteBackward0>)\n",
      "\n",
      "Starting Loss = 0.804374635219574\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(0)  # Random seed\n",
    "\n",
    "def generate_Xs(n):\n",
    "    return torch.rand((n, 2)) * 2 - 1  # Uniform random between -1 and 1\n",
    "\n",
    "def get_Ys(Xs):\n",
    "    return Xs.sum(dim=1, keepdims=True)\n",
    "\n",
    "model = init_Neural_Net(\n",
    "    layer_sizes=(2, 2, 1),\n",
    "    bias=False,\n",
    "    generate_Xs=generate_Xs,\n",
    "    get_Ys=get_Ys\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss = 0.7832100987434387\n",
      "\n",
      "loss = 0.22691687941551208\n",
      "\n",
      "loss = 2.4388882593484595e-05\n",
      "\n",
      "loss = 3.2461384691373496e-09\n",
      "\n",
      "loss = 8.1084677817575e-13\n",
      "\n",
      "Weights:\n",
      "--------\n",
      "hidden_layer_0:\n",
      "tensor([[ 0.8516, -0.9257],\n",
      "        [ 0.8516, -0.9257]], grad_fn=<PermuteBackward0>)\n",
      "\n",
      "output_layer:\n",
      "tensor([[ 1.1742],\n",
      "        [-1.0802]], grad_fn=<PermuteBackward0>)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train(\n",
    "    model,\n",
    "    batches_to_run=500\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Subtraction: f(x1, x2) = x1 - x2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NeuralNetwork(\n",
      "  (NN): Sequential(\n",
      "    (0): Linear(in_features=2, out_features=2, bias=False)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=2, out_features=1, bias=False)\n",
      "  )\n",
      ")\n",
      "\n",
      "Weights:\n",
      "--------\n",
      "hidden_layer_0:\n",
      "tensor([[-0.0053, -0.5820],\n",
      "        [ 0.3793, -0.5204]], grad_fn=<PermuteBackward0>)\n",
      "\n",
      "output_layer:\n",
      "tensor([[-0.2723],\n",
      "        [ 0.1896]], grad_fn=<PermuteBackward0>)\n",
      "\n",
      "Starting Loss = 0.640518069267273\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(0)  # Random seed\n",
    "\n",
    "def generate_Xs(n):\n",
    "    return torch.rand((n, 2)) * 2 - 1  # Uniform random between -1 and 1\n",
    "\n",
    "def get_Ys(Xs):\n",
    "    return (Xs[:, 0] - Xs[:, 1]).unsqueeze(1)\n",
    "\n",
    "model = init_Neural_Net(\n",
    "    layer_sizes=(2, 2, 1),\n",
    "    bias=False,\n",
    "    generate_Xs=generate_Xs,\n",
    "    get_Ys=get_Ys\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss = 0.6367942094802856\n",
      "\n",
      "loss = 0.033380623906850815\n",
      "\n",
      "loss = 4.164157508057542e-05\n",
      "\n",
      "loss = 1.5468325287315565e-08\n",
      "\n",
      "loss = 6.022274259137594e-12\n",
      "\n",
      "Weights:\n",
      "--------\n",
      "hidden_layer_0:\n",
      "tensor([[-0.8518,  0.9320],\n",
      "        [ 0.8518, -0.9320]], grad_fn=<PermuteBackward0>)\n",
      "\n",
      "output_layer:\n",
      "tensor([[-1.1740],\n",
      "        [ 1.0730]], grad_fn=<PermuteBackward0>)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train(\n",
    "    model,\n",
    "    batches_to_run=500\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Minimum Function: f(x1, x2) = min(x1, x2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NeuralNetwork(\n",
      "  (NN): Sequential(\n",
      "    (0): Linear(in_features=2, out_features=3, bias=False)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=3, out_features=1, bias=False)\n",
      "  )\n",
      ")\n",
      "\n",
      "Weights:\n",
      "--------\n",
      "hidden_layer_0:\n",
      "tensor([[-0.0053, -0.5820, -0.2723],\n",
      "        [ 0.3793, -0.5204,  0.1896]], grad_fn=<PermuteBackward0>)\n",
      "\n",
      "output_layer:\n",
      "tensor([[-0.0114],\n",
      "        [ 0.4578],\n",
      "        [-0.0512]], grad_fn=<PermuteBackward0>)\n",
      "\n",
      "Starting Loss = 0.4853660464286804\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(0)  # Random seed\n",
    "\n",
    "def generate_Xs(n):\n",
    "    return torch.rand((n, 2)) * 2 - 1  # Uniform random between -1 and 1\n",
    "\n",
    "def get_Ys(Xs):\n",
    "    return Xs.min(dim=1, keepdims=True).values\n",
    "\n",
    "model = init_Neural_Net(\n",
    "    layer_sizes=(2, 3, 1),\n",
    "    bias=False,\n",
    "    generate_Xs=generate_Xs,\n",
    "    get_Ys=get_Ys\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss = 0.4657897651195526\n",
      "\n",
      "loss = 0.00038561291876249015\n",
      "\n",
      "loss = 1.2959922059962992e-05\n",
      "\n",
      "loss = 5.170457484382496e-07\n",
      "\n",
      "loss = 2.097290519031958e-08\n",
      "\n",
      "loss = 8.531301221026411e-10\n",
      "\n",
      "loss = 3.610790139108033e-11\n",
      "\n",
      "loss = 7.4095920371553e-12\n",
      "\n",
      "loss = 4.984128127577536e-12\n",
      "\n",
      "loss = 4.303819453599367e-12\n",
      "\n",
      "Weights:\n",
      "--------\n",
      "hidden_layer_0:\n",
      "tensor([[ 9.5740e-06, -4.7060e-08, -8.5670e-01],\n",
      "        [ 1.0363e+00, -1.1006e+00,  8.5669e-01]], grad_fn=<PermuteBackward0>)\n",
      "\n",
      "output_layer:\n",
      "tensor([[ 0.9650],\n",
      "        [-0.9086],\n",
      "        [-1.1673]], grad_fn=<PermuteBackward0>)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train(\n",
    "    model,\n",
    "    batches_to_run=10000,  # 10k\n",
    "    print_every=1000  # 1k\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
