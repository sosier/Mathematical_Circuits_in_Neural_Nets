{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mathematical Circuits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Using {DEVICE}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Neural_Net(layer_sizes, bias=True, verbose=True):\n",
    "    assert(len(layer_sizes) >= 2)\n",
    "    \n",
    "    # Get individual layer pieces:\n",
    "    #  - Each layer is linear\n",
    "    #  - All hidden layers have ReLU activation\n",
    "    layers = []\n",
    "    for i in range(len(layer_sizes) - 1):\n",
    "        if i == len(layer_sizes) - 2:  # Last (output) layer\n",
    "            layers += [nn.Linear(layer_sizes[i], layer_sizes[i+1], bias=bias)]\n",
    "        else:\n",
    "            layers += [\n",
    "                nn.Linear(layer_sizes[i], layer_sizes[i+1], bias=bias),\n",
    "                nn.ReLU()\n",
    "            ]\n",
    "    \n",
    "    # Model specification:\n",
    "    class NeuralNetwork(nn.Module):\n",
    "        def __init__(self):\n",
    "            super(NeuralNetwork, self).__init__()\n",
    "            self.NN = nn.Sequential(*layers)\n",
    "\n",
    "        def forward(self, x):\n",
    "            logits = self.NN(x)\n",
    "            return logits\n",
    "        \n",
    "        def print_model_parameters(self):\n",
    "            print(\"Weights:\")\n",
    "            print(\"--------\")\n",
    "\n",
    "            all_weights = list(self.parameters())\n",
    "            for i, layer_weights in enumerate(all_weights):\n",
    "                if i != (len(all_weights) - 1):\n",
    "                    print(f\"hidden_layer_{i}:\")\n",
    "                else:\n",
    "                    print(\"output_layer:\")\n",
    "\n",
    "                print(layer_weights.T)\n",
    "                print(\"\")\n",
    "\n",
    "        def _set_data_generators(self, generate_Xs, get_Ys):\n",
    "            self.generate_Xs = generate_Xs\n",
    "            self.get_Ys = get_Ys\n",
    "\n",
    "        def _init_loss_optimizer(self, lr=1e-4):\n",
    "            self.loss_fn = nn.MSELoss()\n",
    "            self.optimizer = torch.optim.SGD(self.parameters(), lr=lr)\n",
    "\n",
    "        def _init_test_data(self, test_n=1000, verbose=True):\n",
    "            self.test_X = self.generate_Xs(n=test_n)\n",
    "            self.test_y = self.get_Ys(self.test_X)\n",
    "\n",
    "            predicted = self(self.test_X)\n",
    "            loss = self.loss_fn(predicted, self.test_y).item()\n",
    "            if verbose: print(\"Starting Loss =\", loss)\n",
    "    \n",
    "    # Model initialization:\n",
    "    model = NeuralNetwork().to(DEVICE)\n",
    "    if verbose:\n",
    "        print(model)\n",
    "        print(\"\")\n",
    "        model.print_model_parameters()\n",
    "    return model\n",
    "\n",
    "def init_Neural_Net(layer_sizes, generate_Xs, get_Ys, bias=True, lr=1e-4, test_n=1000, verbose=True):\n",
    "    model = Neural_Net(layer_sizes, bias, verbose)\n",
    "    model._set_data_generators(generate_Xs, get_Ys)\n",
    "    model._init_loss_optimizer(lr)\n",
    "    model._init_test_data(test_n, verbose)\n",
    "    return model\n",
    "\n",
    "def train(model, batch_size=1000, batches_to_run=300000):\n",
    "    for i in range(batches_to_run):\n",
    "        # Put model into training mode:\n",
    "        model.train()\n",
    "        \n",
    "        # Get current batch data\n",
    "        train_X = model.generate_Xs(n=batch_size)\n",
    "        train_y = model.get_Ys(train_X)\n",
    "        \n",
    "        # Do forward pass and evaluate loss\n",
    "        predicted = model(train_X)\n",
    "        loss = model.loss_fn(predicted, train_y)\n",
    "\n",
    "        # Backpropagation\n",
    "        model.optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        model.optimizer.step()\n",
    "\n",
    "        # Reporting\n",
    "        if i % 30000 == 0:\n",
    "            model.eval()\n",
    "            predicted = model(model.test_X)\n",
    "            loss = model.loss_fn(predicted, model.test_y)\n",
    "            print(\"loss =\", loss.item())\n",
    "            # model.print_model_parameters()\n",
    "            print(\"\")\n",
    "\n",
    "    model.print_model_parameters()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Identity Function: f(x) = x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NeuralNetwork(\n",
      "  (NN): Sequential(\n",
      "    (0): Linear(in_features=1, out_features=2, bias=False)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=2, out_features=1, bias=False)\n",
      "  )\n",
      ")\n",
      "\n",
      "Weights:\n",
      "--------\n",
      "hidden_layer_0:\n",
      "tensor([[-0.0075,  0.5364]], grad_fn=<PermuteBackward0>)\n",
      "\n",
      "output_layer:\n",
      "tensor([[-0.5820],\n",
      "        [-0.5204]], grad_fn=<PermuteBackward0>)\n",
      "\n",
      "Starting Loss = 0.45063677430152893\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(0)  # Random seed\n",
    "\n",
    "def generate_Xs(n):\n",
    "    return torch.rand((n, 1)) * 2 - 1  # Uniform random between -1 and 1\n",
    "\n",
    "def get_Ys(Xs):\n",
    "    return Xs\n",
    "\n",
    "model = init_Neural_Net(\n",
    "    layer_sizes=(1, 2, 1),\n",
    "    bias=False,\n",
    "    generate_Xs=generate_Xs,\n",
    "    get_Ys=get_Ys\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss = 0.45062240958213806\n",
      "\n",
      "loss = 0.2400665134191513\n",
      "\n",
      "loss = 0.1759452372789383\n",
      "\n",
      "loss = 0.16171278059482574\n",
      "\n",
      "loss = 0.11106877028942108\n",
      "\n",
      "loss = 0.021715493872761726\n",
      "\n",
      "loss = 0.0008291789563372731\n",
      "\n",
      "loss = 1.7237687643500976e-05\n",
      "\n",
      "loss = 4.432341427218489e-07\n",
      "\n",
      "loss = 1.9709477783180773e-07\n",
      "\n",
      "Weights:\n",
      "--------\n",
      "hidden_layer_0:\n",
      "tensor([[-0.9192,  1.0035]], grad_fn=<PermuteBackward0>)\n",
      "\n",
      "output_layer:\n",
      "tensor([[-1.0872],\n",
      "        [ 0.9957]], grad_fn=<PermuteBackward0>)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train(\n",
    "    model,\n",
    "    batches_to_run=300000  # 300k\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Negative Identity Function: f(x) = -x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NeuralNetwork(\n",
      "  (NN): Sequential(\n",
      "    (0): Linear(in_features=1, out_features=2, bias=False)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=2, out_features=1, bias=False)\n",
      "  )\n",
      ")\n",
      "\n",
      "Weights:\n",
      "--------\n",
      "hidden_layer_0:\n",
      "tensor([[ 0.5153, -0.4414]], grad_fn=<PermuteBackward0>)\n",
      "\n",
      "output_layer:\n",
      "tensor([[-0.1371],\n",
      "        [ 0.3319]], grad_fn=<PermuteBackward0>)\n",
      "\n",
      "Starting Loss = 0.26709434390068054\n"
     ]
    }
   ],
   "source": [
    "# NOTE: Random seed 0 gets stuck in a local optimum where it works very well for positive inputs,\n",
    "# but always returns 0 for negative inputs:\n",
    "torch.manual_seed(1)  # Random seed\n",
    "\n",
    "def generate_Xs(n):\n",
    "    return torch.rand((n, 1)) * 2 - 1  # Uniform random between -1 and 1\n",
    "\n",
    "def get_Ys(Xs):\n",
    "    return Xs * -1\n",
    "\n",
    "model = init_Neural_Net(\n",
    "    layer_sizes=(1, 2, 1),\n",
    "    bias=False,\n",
    "    generate_Xs=generate_Xs,\n",
    "    get_Ys=get_Ys\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss = 0.2670891582965851\n",
      "\n",
      "loss = 0.07879319787025452\n",
      "\n",
      "loss = 0.004247117787599564\n",
      "\n",
      "loss = 9.394864173373207e-05\n",
      "\n",
      "loss = 1.610331992196734e-06\n",
      "\n",
      "loss = 2.0403335554419755e-07\n",
      "\n",
      "loss = 1.9260137662513444e-07\n",
      "\n",
      "loss = 1.8912245991486998e-07\n",
      "\n",
      "loss = 1.8678449009712494e-07\n",
      "\n",
      "loss = 1.849424222655216e-07\n",
      "\n",
      "Weights:\n",
      "--------\n",
      "hidden_layer_0:\n",
      "tensor([[ 1.0627, -1.0206]], grad_fn=<PermuteBackward0>)\n",
      "\n",
      "output_layer:\n",
      "tensor([[-0.9403],\n",
      "        [ 0.9790]], grad_fn=<PermuteBackward0>)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train(\n",
    "    model,\n",
    "    batches_to_run=300000  # 300k\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Absolute Value: f(x) = |x|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NeuralNetwork(\n",
      "  (NN): Sequential(\n",
      "    (0): Linear(in_features=1, out_features=2, bias=False)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=2, out_features=1, bias=False)\n",
      "  )\n",
      ")\n",
      "\n",
      "Weights:\n",
      "--------\n",
      "hidden_layer_0:\n",
      "tensor([[ 0.5153, -0.4414]], grad_fn=<PermuteBackward0>)\n",
      "\n",
      "output_layer:\n",
      "tensor([[-0.1371],\n",
      "        [ 0.3319]], grad_fn=<PermuteBackward0>)\n",
      "\n",
      "Starting Loss = 0.31527942419052124\n"
     ]
    }
   ],
   "source": [
    "# NOTE: Random seed 0 gets stuck in a local optimum where the weight one of the hidden nodes gets zeroed out.\n",
    "# As a result ends up working for only positive inputs, but always returns 0 for negative inputs:\n",
    "torch.manual_seed(1)  # Random seed\n",
    "\n",
    "def generate_Xs(n):\n",
    "    return torch.rand((n, 1)) * 2 - 1  # Uniform random between -1 and 1\n",
    "\n",
    "def get_Ys(Xs):\n",
    "    return torch.abs(Xs)\n",
    "\n",
    "model = init_Neural_Net(\n",
    "    layer_sizes=(1, 2, 1),\n",
    "    bias=False,\n",
    "    generate_Xs=generate_Xs,\n",
    "    get_Ys=get_Ys\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss = 0.31527337431907654\n",
      "\n",
      "loss = 0.1359097808599472\n",
      "\n",
      "loss = 0.017552969977259636\n",
      "\n",
      "loss = 0.0005560762365348637\n",
      "\n",
      "loss = 1.0874651707126759e-05\n",
      "\n",
      "loss = 3.6069971542929125e-07\n",
      "\n",
      "loss = 1.9506188664308866e-07\n",
      "\n",
      "loss = 1.9009961249594198e-07\n",
      "\n",
      "loss = 1.8731030593244213e-07\n",
      "\n",
      "loss = 1.8525956591020076e-07\n",
      "\n",
      "Weights:\n",
      "--------\n",
      "hidden_layer_0:\n",
      "tensor([[ 1.0627, -1.0206]], grad_fn=<PermuteBackward0>)\n",
      "\n",
      "output_layer:\n",
      "tensor([[0.9403],\n",
      "        [0.9790]], grad_fn=<PermuteBackward0>)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train(\n",
    "    model,\n",
    "    batches_to_run=300000  # 300k\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Addition: f(x1, x2) = x1 + x2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NeuralNetwork(\n",
      "  (NN): Sequential(\n",
      "    (0): Linear(in_features=2, out_features=2, bias=False)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=2, out_features=1, bias=False)\n",
      "  )\n",
      ")\n",
      "\n",
      "Weights:\n",
      "--------\n",
      "hidden_layer_0:\n",
      "tensor([[-0.0053, -0.5820],\n",
      "        [ 0.3793, -0.5204]], grad_fn=<PermuteBackward0>)\n",
      "\n",
      "output_layer:\n",
      "tensor([[-0.2723],\n",
      "        [ 0.1896]], grad_fn=<PermuteBackward0>)\n",
      "\n",
      "Starting Loss = 0.804374635219574\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(0)  # Random seed\n",
    "\n",
    "def generate_Xs(n):\n",
    "    return torch.rand((n, 2)) * 2 - 1  # Uniform random between -1 and 1\n",
    "\n",
    "def get_Ys(Xs):\n",
    "    return Xs.sum(dim=1, keepdims=True)\n",
    "\n",
    "model = init_Neural_Net(\n",
    "    layer_sizes=(2, 2, 1),\n",
    "    bias=False,\n",
    "    generate_Xs=generate_Xs,\n",
    "    get_Ys=get_Ys\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss = 0.8043529391288757\n",
      "\n",
      "loss = 0.4202917516231537\n",
      "\n",
      "loss = 0.345365971326828\n",
      "\n",
      "loss = 0.2909817397594452\n",
      "\n",
      "loss = 0.06650708615779877\n",
      "\n",
      "loss = 0.0024126311764121056\n",
      "\n",
      "loss = 0.0001487390254624188\n",
      "\n",
      "loss = 1.0628493328113109e-05\n",
      "\n",
      "loss = 8.306866448037908e-07\n",
      "\n",
      "loss = 3.158412766879337e-07\n",
      "\n",
      "Weights:\n",
      "--------\n",
      "hidden_layer_0:\n",
      "tensor([[ 0.8511, -0.9304],\n",
      "        [ 0.8522, -0.9291]], grad_fn=<PermuteBackward0>)\n",
      "\n",
      "output_layer:\n",
      "tensor([[ 1.1742],\n",
      "        [-1.0755]], grad_fn=<PermuteBackward0>)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train(\n",
    "    model,\n",
    "    batches_to_run=300000  # 300k\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Subtraction: f(x1, x2) = x1 - x2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NeuralNetwork(\n",
      "  (NN): Sequential(\n",
      "    (0): Linear(in_features=2, out_features=2, bias=False)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=2, out_features=1, bias=False)\n",
      "  )\n",
      ")\n",
      "\n",
      "Weights:\n",
      "--------\n",
      "hidden_layer_0:\n",
      "tensor([[-0.0053, -0.5820],\n",
      "        [ 0.3793, -0.5204]], grad_fn=<PermuteBackward0>)\n",
      "\n",
      "output_layer:\n",
      "tensor([[-0.2723],\n",
      "        [ 0.1896]], grad_fn=<PermuteBackward0>)\n",
      "\n",
      "Starting Loss = 0.640518069267273\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(0)  # Random seed\n",
    "\n",
    "def generate_Xs(n):\n",
    "    return torch.rand((n, 2)) * 2 - 1  # Uniform random between -1 and 1\n",
    "\n",
    "def get_Ys(Xs):\n",
    "    return (Xs[:, 0] - Xs[:, 1]).unsqueeze(1)\n",
    "\n",
    "model = init_Neural_Net(\n",
    "    layer_sizes=(2, 2, 1),\n",
    "    bias=False,\n",
    "    generate_Xs=generate_Xs,\n",
    "    get_Ys=get_Ys\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss = 0.6405144333839417\n",
      "\n",
      "loss = 0.42583832144737244\n",
      "\n",
      "loss = 0.23183923959732056\n",
      "\n",
      "loss = 0.05851614475250244\n",
      "\n",
      "loss = 0.01078260038048029\n",
      "\n",
      "loss = 0.0016846817452460527\n",
      "\n",
      "loss = 0.0001997139333980158\n",
      "\n",
      "loss = 2.0616595065803267e-05\n",
      "\n",
      "loss = 2.022708258664352e-06\n",
      "\n",
      "loss = 3.452058763286914e-07\n",
      "\n",
      "Weights:\n",
      "--------\n",
      "hidden_layer_0:\n",
      "tensor([[-0.8519,  0.9296],\n",
      "        [ 0.8508, -0.9309]], grad_fn=<PermuteBackward0>)\n",
      "\n",
      "output_layer:\n",
      "tensor([[-1.1746],\n",
      "        [ 1.0750]], grad_fn=<PermuteBackward0>)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train(\n",
    "    model,\n",
    "    batches_to_run=300000  # 300k\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Minimum Function: f(x1, x2) = min(x1, x2)\n",
    "\n",
    "(Currently gets stuck in local minimum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NeuralNetwork(\n",
      "  (NN): Sequential(\n",
      "    (0): Linear(in_features=2, out_features=3, bias=False)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=3, out_features=2, bias=False)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=2, out_features=1, bias=False)\n",
      "  )\n",
      ")\n",
      "\n",
      "Weights:\n",
      "--------\n",
      "hidden_layer_0:\n",
      "tensor([[ 0.3643, -0.1371, -0.6657],\n",
      "        [-0.3121,  0.3319,  0.4241]], grad_fn=<PermuteBackward0>)\n",
      "\n",
      "hidden_layer_1:\n",
      "tensor([[-0.1188, -0.0707],\n",
      "        [ 0.2937,  0.1601],\n",
      "        [ 0.0803,  0.0285]], grad_fn=<PermuteBackward0>)\n",
      "\n",
      "output_layer:\n",
      "tensor([[ 0.2583],\n",
      "        [-0.2756]], grad_fn=<PermuteBackward0>)\n",
      "\n",
      "Starting Loss = 0.33890464901924133\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(0)  # Random seed\n",
    "\n",
    "def generate_Xs(n):\n",
    "    return torch.rand((n, 2)) * 2 - 1  # Uniform random between -1 and 1\n",
    "\n",
    "def get_Ys(Xs):\n",
    "    return Xs.min(dim=1, keepdims=True).values\n",
    "\n",
    "model = init_Neural_Net(\n",
    "    layer_sizes=(2, 3, 2, 1),\n",
    "    bias=False,\n",
    "    generate_Xs=generate_Xs,\n",
    "    get_Ys=get_Ys\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss = 0.33890366554260254\n",
      "\n",
      "loss = 0.3093772232532501\n",
      "\n",
      "loss = 0.24279135465621948\n",
      "\n",
      "loss = 0.16426093876361847\n",
      "\n",
      "loss = 0.14048132300376892\n",
      "\n",
      "loss = 0.13215050101280212\n",
      "\n",
      "loss = 0.12342052906751633\n",
      "\n",
      "loss = 0.09989515691995621\n",
      "\n",
      "loss = 0.0739549994468689\n",
      "\n",
      "loss = 0.06282414495944977\n",
      "\n",
      "loss = 0.05912776291370392\n",
      "\n",
      "loss = 0.05712759494781494\n",
      "\n",
      "loss = 0.0558374784886837\n",
      "\n",
      "loss = 0.05497528240084648\n",
      "\n",
      "loss = 0.05437467247247696\n",
      "\n",
      "loss = 0.05397646501660347\n",
      "\n",
      "loss = 0.05370553582906723\n",
      "\n",
      "loss = 0.05352906510233879\n",
      "\n",
      "loss = 0.053397610783576965\n",
      "\n",
      "loss = 0.053293194621801376\n",
      "\n",
      "loss = 0.05321613699197769\n",
      "\n",
      "loss = 0.0531618557870388\n",
      "\n",
      "loss = 0.05312013253569603\n",
      "\n",
      "loss = 0.05308714136481285\n",
      "\n",
      "loss = 0.05306166037917137\n",
      "\n",
      "loss = 0.05304386094212532\n",
      "\n",
      "loss = 0.05303012579679489\n",
      "\n",
      "loss = 0.05302044004201889\n",
      "\n",
      "loss = 0.05301380902528763\n",
      "\n",
      "loss = 0.053008321672677994\n",
      "\n",
      "loss = 0.053004421293735504\n",
      "\n",
      "loss = 0.05300185829401016\n",
      "\n",
      "loss = 0.052999347448349\n",
      "\n",
      "loss = 0.052997689694166183\n",
      "\n",
      "loss = 0.052995797246694565\n",
      "\n",
      "loss = 0.052994076162576675\n",
      "\n",
      "loss = 0.052992355078458786\n",
      "\n",
      "loss = 0.0529911145567894\n",
      "\n",
      "loss = 0.05298967286944389\n",
      "\n",
      "loss = 0.05298798531293869\n",
      "\n",
      "loss = 0.052986085414886475\n",
      "\n",
      "loss = 0.05298435315489769\n",
      "\n",
      "loss = 0.052982866764068604\n",
      "\n",
      "loss = 0.05298110842704773\n",
      "\n",
      "loss = 0.05297919362783432\n",
      "\n",
      "loss = 0.052976783365011215\n",
      "\n",
      "loss = 0.0529746450483799\n",
      "\n",
      "loss = 0.05297283083200455\n",
      "\n",
      "loss = 0.05297079309821129\n",
      "\n",
      "loss = 0.052968285977840424\n",
      "\n",
      "loss = 0.0529659241437912\n",
      "\n",
      "loss = 0.052963342517614365\n",
      "\n",
      "loss = 0.05296066403388977\n",
      "\n",
      "loss = 0.05295811593532562\n",
      "\n",
      "loss = 0.052955057471990585\n",
      "\n",
      "loss = 0.052952177822589874\n",
      "\n",
      "loss = 0.052948955446481705\n",
      "\n",
      "loss = 0.05294543132185936\n",
      "\n",
      "loss = 0.052941758185625076\n",
      "\n",
      "loss = 0.05293789505958557\n",
      "\n",
      "loss = 0.05293414369225502\n",
      "\n",
      "loss = 0.052930038422346115\n",
      "\n",
      "loss = 0.052925512194633484\n",
      "\n",
      "loss = 0.052920736372470856\n",
      "\n",
      "loss = 0.05291646346449852\n",
      "\n",
      "loss = 0.05291128531098366\n",
      "\n",
      "loss = 0.052905838936567307\n",
      "\n",
      "loss = 0.052900101989507675\n",
      "\n",
      "loss = 0.05289414897561073\n",
      "\n",
      "loss = 0.05288776010274887\n",
      "\n",
      "loss = 0.052881043404340744\n",
      "\n",
      "loss = 0.052873868495225906\n",
      "\n",
      "loss = 0.05286634340882301\n",
      "\n",
      "loss = 0.05285800248384476\n",
      "\n",
      "loss = 0.052849166095256805\n",
      "\n",
      "loss = 0.05283991992473602\n",
      "\n",
      "loss = 0.052829619497060776\n",
      "\n",
      "loss = 0.05281895399093628\n",
      "\n",
      "loss = 0.05280718579888344\n",
      "\n",
      "loss = 0.052794791758060455\n",
      "\n",
      "loss = 0.052781783044338226\n",
      "\n",
      "loss = 0.05276746675372124\n",
      "\n",
      "loss = 0.05275191366672516\n",
      "\n",
      "loss = 0.05273473635315895\n",
      "\n",
      "loss = 0.052716393023729324\n",
      "\n",
      "loss = 0.052696119993925095\n",
      "\n",
      "loss = 0.05267412215471268\n",
      "\n",
      "loss = 0.05264933407306671\n",
      "\n",
      "loss = 0.052620962262153625\n",
      "\n",
      "loss = 0.052588578313589096\n",
      "\n",
      "loss = 0.05255093425512314\n",
      "\n",
      "loss = 0.05250701680779457\n",
      "\n",
      "loss = 0.05245401710271835\n",
      "\n",
      "loss = 0.05238848924636841\n",
      "\n",
      "loss = 0.05230436101555824\n",
      "\n",
      "loss = 0.05219331383705139\n",
      "\n",
      "loss = 0.05203693360090256\n",
      "\n",
      "loss = 0.05179869011044502\n",
      "\n",
      "loss = 0.05139084905385971\n",
      "\n",
      "loss = 0.050543855875730515\n",
      "\n",
      "Weights:\n",
      "--------\n",
      "hidden_layer_0:\n",
      "tensor([[ 0.1842, -0.3122, -1.0522],\n",
      "        [-0.9267,  0.4488,  0.2205]], grad_fn=<PermuteBackward0>)\n",
      "\n",
      "hidden_layer_1:\n",
      "tensor([[-0.1116,  0.8180],\n",
      "        [ 0.5260,  0.0726],\n",
      "        [-0.2124,  0.7034]], grad_fn=<PermuteBackward0>)\n",
      "\n",
      "output_layer:\n",
      "tensor([[ 0.5414],\n",
      "        [-1.1017]], grad_fn=<PermuteBackward0>)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train(\n",
    "    model,\n",
    "    batches_to_run=3000000  # 3M\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
